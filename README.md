# E-Commerce Cloud Platform - Multi-Cloud Microservices

[![AWS](https://img.shields.io/badge/AWS-EKS%20%7C%20RDS%20%7C%20DynamoDB%20%7C%20MSK-orange)](https://aws.amazon.com)
[![GCP](https://img.shields.io/badge/GCP-Dataproc%20%7C%20Flink-blue)](https://cloud.google.com)
[![Terraform](https://img.shields.io/badge/IaC-Terraform-purple)](https://terraform.io)
[![Kubernetes](https://img.shields.io/badge/K8s-EKS%20%7C%20ArgoCD-326CE5)](https://kubernetes.io)
[![Status](https://img.shields.io/badge/Status-Production%20Ready-success)](https://github.com)

> **Enterprise-grade cloud-native e-commerce platform** with 6 microservices, serverless functions, real-time stream processing, GitOps deployment, and hybrid multi-cloud architecture.

---

## üéØ Project Overview

A complete cloud-native e-commerce platform demonstrating **modern cloud architecture patterns**:
- **6 microservices** on AWS EKS with auto-scaling
- **Real-time analytics** with Apache Flink on GCP Dataproc
- **Event-driven architecture** using Kafka (AWS MSK)
- **GitOps deployments** via ArgoCD
- **100% Infrastructure as Code** with Terraform
- **Full observability** with Prometheus & Grafana

---

## üèóÔ∏è Architecture

### **Multi-Cloud Setup**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ AWS (Provider A) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ
‚îÇ  ‚îÇ EKS Cluster ‚îÇ‚îÄ‚îÄ‚ñ∂‚îÇ   Services   ‚îÇ‚îÄ‚îÄ‚ñ∂‚îÇ   Storage    ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ (K8s 1.28)  ‚îÇ   ‚îÇ 6 Microservices‚îÇ   ‚îÇ RDS/DynamoDB ‚îÇ        ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ
‚îÇ                            ‚îÇ                                     ‚îÇ
‚îÇ                            ‚ñº                                     ‚îÇ
‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                            ‚îÇ
‚îÇ                    ‚îÇ  MSK Kafka   ‚îÇ                            ‚îÇ
‚îÇ                    ‚îÇ  (Messaging) ‚îÇ                            ‚îÇ
‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
              Cross-Cloud Event Stream
                            ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ GCP (Provider B) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                           ‚ñº                                      ‚îÇ
‚îÇ                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                            ‚îÇ
‚îÇ                   ‚îÇ   Dataproc    ‚îÇ                            ‚îÇ
‚îÇ                   ‚îÇ Apache Flink  ‚îÇ                            ‚îÇ
‚îÇ                   ‚îÇ Stream Process‚îÇ                            ‚îÇ
‚îÇ                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                            ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### **Microservices Architecture**

1. **API Gateway** (`/api`)
   - Public REST API with CORS
   - Request routing and orchestration
   - **HPA:** 2-10 pods (CPU/Memory)

2. **User Service** (`/api/users`)
   - User management and authentication
   - Storage: RDS MySQL

3. **Product Service** (`/api/products`)
   - Product catalog management
   - Storage: DynamoDB (NoSQL)

4. **Order Service** (`/api/orders`)
   - Order processing and tracking
   - Publishes events to Kafka
   - Storage: RDS MySQL
   - **HPA:** 2-8 pods (CPU/Memory)

5. **Notification Service**
   - Event-driven notifications
   - Consumes Kafka events
   - Sends alerts via SNS/Email

6. **Analytics Service** (`/api/analytics`)
   - Analytics aggregation
   - Real-time metrics
   - Storage: DynamoDB

7. **Lambda Function** (Serverless)
   - S3-triggered file processing
   - Event-driven compute

### **Stream Processing (GCP)**

- **Apache Flink** on Dataproc
- Consumes order events from AWS MSK
- 1-minute tumbling window aggregations
- Publishes results back to Kafka

---

## üìÅ Project Structure

```
Cloud_A15/
‚îú‚îÄ‚îÄ microservices/              # 6 Flask microservices
‚îÇ   ‚îú‚îÄ‚îÄ api-gateway/           # Public API (Port 5000)
‚îÇ   ‚îú‚îÄ‚îÄ user-service/          # User mgmt (Port 5001)
‚îÇ   ‚îú‚îÄ‚îÄ product-service/       # Products (Port 5002)
‚îÇ   ‚îú‚îÄ‚îÄ order-service/         # Orders (Port 5003)
‚îÇ   ‚îú‚îÄ‚îÄ notification-service/  # Events (Port 5004)
‚îÇ   ‚îî‚îÄ‚îÄ analytics-service/     # Analytics (Port 5005)
‚îÇ
‚îú‚îÄ‚îÄ terraform/                  # Infrastructure as Code
‚îÇ   ‚îú‚îÄ‚îÄ aws/                   # AWS resources (EKS, RDS, etc.)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.tf           # 48+ resources
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ modules/          # Reusable modules
‚îÇ   ‚îî‚îÄ‚îÄ gcp/                   # GCP resources (Dataproc)
‚îÇ       ‚îî‚îÄ‚îÄ main.tf
‚îÇ
‚îú‚îÄ‚îÄ kubernetes/                 # K8s manifests
‚îÇ   ‚îú‚îÄ‚îÄ base/                  # Deployments, Services, HPAs
‚îÇ   ‚îî‚îÄ‚îÄ argocd/                # GitOps applications
‚îÇ       ‚îî‚îÄ‚îÄ applications/
‚îÇ
‚îú‚îÄ‚îÄ analytics/                  # Flink job (Java/Maven)
‚îÇ   ‚îú‚îÄ‚îÄ src/main/java/
‚îÇ   ‚îî‚îÄ‚îÄ pom.xml
‚îÇ
‚îú‚îÄ‚îÄ lambda/                     # Serverless functions
‚îÇ   ‚îî‚îÄ‚îÄ s3-processor.py
‚îÇ
‚îú‚îÄ‚îÄ frontend/                   # Web UI
‚îÇ   ‚îú‚îÄ‚îÄ index.html             # Original UI
‚îÇ   ‚îî‚îÄ‚îÄ app.html               # Enhanced UI
‚îÇ
‚îú‚îÄ‚îÄ load-testing/              # k6 load tests
‚îÇ   ‚îî‚îÄ‚îÄ load-test.js
‚îÇ
‚îú‚îÄ‚îÄ docs/                       # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ DESIGN.md             # Architecture design
‚îÇ   ‚îî‚îÄ‚îÄ API.md                # API documentation
‚îÇ
‚îú‚îÄ‚îÄ DEPLOYMENT_GUIDE.md        # Full deployment steps
‚îú‚îÄ‚îÄ GCP_SETUP_GUIDE.md         # GCP integration guide
‚îú‚îÄ‚îÄ REQUIREMENTS_VERIFICATION.md # Assignment checklist
‚îú‚îÄ‚îÄ VIDEO_DEMO_GUIDE.md        # Demo script
‚îî‚îÄ‚îÄ README.md                  # This file
```

---

## üöÄ Quick Start

### Prerequisites

```bash
# Required tools
- AWS CLI (configured)
- kubectl
- Terraform >= 1.5
- Docker
- Helm 3
- k6 (for load testing)
- gcloud CLI (for GCP)

# Install on macOS
brew install awscli kubectl terraform docker helm k6 google-cloud-sdk
```

### 1. Deploy AWS Infrastructure

```bash
# Clone repository
git clone https://github.com/pranjaymalhotra/CloudAssignment.git
cd CloudAssignment

# Deploy AWS resources (20-30 minutes)
cd terraform/aws
terraform init
terraform apply -auto-approve

# Save outputs
terraform output > ../../aws-outputs.txt
```

### 2. Deploy Microservices to EKS

```bash
# Configure kubectl
aws eks update-kubeconfig --region us-east-1 --name ecommerce-cluster

# Install ArgoCD
kubectl create namespace argocd
kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml

# Deploy microservices via ArgoCD
kubectl apply -f kubernetes/argocd/applications/

# Wait for services
kubectl get pods --watch
```

### 3. Deploy GCP Flink Processing

```bash
# Configure GCP
gcloud auth login
gcloud config set project YOUR_PROJECT_ID

# Deploy GCP infrastructure
cd terraform/gcp
terraform init
terraform apply -auto-approve

# Build and deploy Flink job
cd ../../analytics
mvn clean package
gsutil cp target/flink-analytics-1.0.0.jar gs://YOUR_BUCKET/

# Submit Flink job (see GCP_SETUP_GUIDE.md)
gcloud dataproc jobs submit flink --cluster=analytics-cluster ...
```

### 4. Install Observability Stack

```bash
# Install Prometheus + Grafana
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm install prometheus prometheus-community/kube-prometheus-stack

# Access Grafana
kubectl port-forward svc/prometheus-grafana 3000:80
# Open http://localhost:3000 (admin/prom-operator)
```

### 5. Run Load Tests

```bash
# Get API Gateway URL
export API_URL=$(kubectl get svc api-gateway -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')

# Run k6 load test
cd load-testing
k6 run load-test.js

# Watch HPA scaling
kubectl get hpa --watch
```

---

## üé® Frontend

### **Enhanced Web UI**

Open `frontend/app.html` in your browser:

**Features:**
- üõçÔ∏è Product catalog with search
- üõí Shopping cart management
- üì¶ Order history
- üë§ User profiles
- üì± Mobile responsive design
- ‚ö° Real-time API status

**Original Demo UI:** `frontend/index.html`

---

## üìä Monitoring & Observability

### Prometheus Metrics
```bash
kubectl port-forward svc/prometheus-kube-prometheus-prometheus 9090:9090
# Open http://localhost:9090
```

### Grafana Dashboards
```bash
kubectl port-forward svc/prometheus-grafana 3000:80
# Open http://localhost:3000
```

**Pre-configured Dashboards:**
- Kubernetes cluster health
- Pod CPU/Memory usage
- Request rate (RPS)
- Error rate
- Response latency (p50, p95, p99)

### Application Logs
```bash
# View service logs
kubectl logs -l app=api-gateway --tail=50 -f
kubectl logs -l app=order-service --tail=50 -f

# View all pods
kubectl logs --all-containers=true --tail=50 -f
```

---

## üß™ Testing

### Automated Tests
```bash
# Run API tests
./test-api.sh

# Expected: 17+ passing tests
```

### Load Testing
```bash
# Run sustained load (5 minutes)
k6 run load-testing/load-test.js

# Observe HPA scaling
kubectl get hpa --watch
```

### Manual Testing
```bash
# Get API URL
API_URL=$(kubectl get svc api-gateway -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')

# Health check
curl http://$API_URL/health

# Create user
curl -X POST http://$API_URL/api/users \
  -H "Content-Type: application/json" \
  -d '{"name":"John Doe","email":"john@example.com"}'

# Get all users
curl http://$API_URL/api/users
```

---

## üìö Documentation

| Document | Description |
|----------|-------------|
| [DEPLOYMENT_GUIDE.md](DEPLOYMENT_GUIDE.md) | Complete deployment instructions |
| [GCP_SETUP_GUIDE.md](GCP_SETUP_GUIDE.md) | GCP Dataproc + Flink setup |
| [REQUIREMENTS_VERIFICATION.md](REQUIREMENTS_VERIFICATION.md) | Requirements checklist |
| [VIDEO_DEMO_GUIDE.md](VIDEO_DEMO_GUIDE.md) | Demo script for recording |
| [TESTING_GUIDE.md](TESTING_GUIDE.md) | Testing procedures |
| [docs/DESIGN.md](docs/DESIGN.md) | Architecture design document |
| [docs/API.md](docs/API.md) | API documentation |

---

## üîÑ GitOps with ArgoCD

**All deployments managed via Git:**

```bash
# Access ArgoCD UI
kubectl port-forward svc/argocd-server -n argocd 8080:443

# Get admin password
kubectl -n argocd get secret argocd-initial-admin-secret \
  -o jsonpath="{.data.password}" | base64 -d

# Open https://localhost:8080
# Username: admin
```

**Application Configuration:**
- Source: GitHub repository
- Path: `kubernetes/base/`
- Sync: Automated with self-heal
- No manual `kubectl apply` needed!

---

## üí∞ Cost Estimation

### AWS Resources (per hour):
- EKS cluster: $0.10
- EC2 nodes (2 √ó t3.medium): $0.08
- RDS MySQL (db.t3.micro): $0.017
- DynamoDB: On-demand (~$0.01)
- MSK (kafka.t3.small): $0.12
- NAT Gateways: $0.09
- Load Balancers: $0.05
- **Total AWS:** ~$0.47/hour (~$11/day)

### GCP Resources (per hour):
- Dataproc (1 master + 2 workers): $0.31
- Cloud Storage: ~$0.01
- **Total GCP:** ~$0.32/hour (~$7.68/day)

**Combined:** ~$0.79/hour or **~$19/day**

### üí° Cost Savings:
- Stop Dataproc when not testing
- Use spot/preemptible instances
- Delete after demo
- Free tier credits available

---

## üßπ Cleanup

### Destroy AWS Resources
```bash
cd terraform/aws
terraform destroy -auto-approve
```

### Destroy GCP Resources
```bash
cd terraform/gcp
terraform destroy -auto-approve
```

### Quick Teardown
```bash
./teardown.sh  # Automated cleanup script
```

---

## ‚úÖ Requirements Verification

All 8 assignment requirements fully implemented:

| Requirement | Status | Details |
|-------------|--------|---------|
| a. Infrastructure as Code | ‚úÖ 100% | Terraform for all resources |
| b. 6 Microservices + Serverless | ‚úÖ 100% | 6 services + Lambda |
| c. Kubernetes + HPA | ‚úÖ 100% | EKS with 2 HPAs |
| d. GitOps (ArgoCD) | ‚úÖ 100% | Automated deployments |
| e. Flink Stream Processing | ‚úÖ 100% | GCP Dataproc with Kafka |
| f. 3 Storage Types | ‚úÖ 100% | S3 + RDS + DynamoDB |
| g. Observability | ‚úÖ 100% | Prometheus + Grafana + Logs |
| h. Load Testing | ‚úÖ 100% | k6 with HPA validation |

**See [REQUIREMENTS_VERIFICATION.md](REQUIREMENTS_VERIFICATION.md) for detailed proof.**

---

## üìπ Video Demos

### Individual Video (`<idno>_video.txt`)
- Code walkthrough for each microservice
- Terraform configurations explained
- Your contributions highlighted

### Demo Video (`demo_video.txt`)
- End-to-end system demonstration
- Load testing with HPA scaling
- Cross-cloud Flink processing
- Observability dashboards
- GitOps deployments

---

## ü§ù Contributing

This is an academic project. For questions or improvements:

1. Fork the repository
2. Create a feature branch
3. Submit a pull request

---

## üìÑ License

Educational project for Cloud Computing assignment.

---

## üôè Acknowledgments

- AWS for EKS, RDS, DynamoDB, MSK, Lambda
- Google Cloud for Dataproc and Flink
- Apache Flink for stream processing
- ArgoCD for GitOps
- Prometheus & Grafana for observability
- k6 for load testing

---

## üìû Support

For issues or questions:
- Check documentation in `/docs`
- Review deployment guides
- See troubleshooting in guides

---

**Project Status:** ‚úÖ Production Ready | üìù All Requirements Met | üéØ Ready for Submission

Made with ‚òÅÔ∏è by Pranjay Malhotra
